apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "esgf-compute-wps.fullname" . }}-dask
  labels:
    app.kubernetes.io/managed-by: {{ $.Release.Service }}
    app.kubernetes.io/instance: {{ $.Release.Name }}
    app.kubernetes.io/name: {{ template "esgf-compute-wps.name" $ }}
    helm.sh/chart: {{ $.Chart.Name }}-{{ $.Chart.Version }}
data:
  worker-spec.yml: |
    kind: Pod
    metadata:
      labels:
        dask: worker
    spec:
      restartPolicy: Never
      {{- if .Values.wps.nodeSelector }}
      nodeSelector: 
        {{ .Values.wps.nodeSelector | toYaml | trimSuffix "\n" }}
      {{- end }}
      containers:
      - image: {{ .Values.dask.image }}:{{ .Values.dask.imageTag }}
        imagePullPolicy: Always
        env:
        - name: CDAT_ANONYMOUS_LOG
          value: 'no'
        command: 
        - dask-worker
        - --no-bokeh
        - --nthreads
        - '{{ $.Values.dask.nthreads }}'
        - --nprocs
        - '{{ $.Values.dask.nprocs }}'
        - --memory-limit
        - {{ $.Values.dask.memoryLimit }}
        - --death-timeout
        - '60'
        - {{ template "esgf-compute-wps.fullname" . }}-dask-scheduler:8786
        name: dask
        {{- if and $.Values.dask.resources (not $.Values.development) (not $.Values.ignoreResources) }}
        resources: {{ $.Values.dask.resources | toYaml | trimSuffix "\n" | nindent 10 }}
        {{- end }}
        volumeMounts:
        - mountPath: /data/public
          name: public-volume
          subPath: public
      volumes:
      - name: public-volume
        persistentVolumeClaim:
          claimName: public-pvc
