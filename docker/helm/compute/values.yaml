# This chart provides default resource requests and limits for each container. If
# this is not desired each "requests:" may be replaced with "requests: null".

# Run the chart in development mode, this will start the celery and wps containers
# with /bin/sleep infinity and each container will need to have their respective
# application run manually. This allows for live code editing in the environment.
development: false

# Internal HTTP/TCP load balancer
traefik:
  serviceType: NodePort

  rbac:
    enabled: true

  ssl:
    enabled: true
    enforced: true
    tlsMinVersion: VersionTLS12
    cipherSuites:
    - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
    - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
    - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
    - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
    - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
    - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
    - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
    - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
    - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
    - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
    - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
    - TLS_ECDHE_ECDSA_WITH_RC4_128_SHA
    generateTLS: true
    
  dashboard:
    enabled: true
    domain: ""
    ingress:
      annotations:
        traefik.ingress.kubernetes.io/rule-type: PathPrefixStrip
      labels:
        traffic-type: external

  kubernetes:
    labelSelector: traffic-type=internal

  metrics:
    prometheus:
      enabled: true
      restrictAccess: true

# Persistence
# 
# For each entry below a PersistentVolume (PV) and PersistentVolumeClaim (PVC) is created.
# The created PVs will use the path value to populate HostPath types. If dynamic provisioning
# is required each path value will need to be deleted and the appropriate storageClassName
# will need to be set. This will prevent the chart from creating PersistenVolume allowing
# the PVCs to bind to the PVs created by the dynamic provisioner. e.g.
#
# persistence:
#   public:
#     path: ...
#
# persistence:
#   public:
#     storageClassName: cephfs-default # Storage class that will be used for the PVs
#     path: null
persistence:
  public:
    storageClassName: slow
    capacity: 100Gi
    path: /p/cscratch/nimbus/wps/data/public

  postgresql:
    storageClassName: slow
    capacity: 10Gi
    path: /opt/nimbus/wps/postgresql

  redis:
    storageClassName: slow
    capacity: 10Gi
    path: /opt/nimbus/wps/redis

# Provisioner
provisioner:
  nodeSelector: {}

  image: jasonb87/compute-provisioner
  imageTag: 0.1.0

  imagePullPolicy: Always

  frontendPort: 7777
  backendPort: 7778

  resources: {}

# Kubernetes Monitor
kubeMonitor:
  nodeSelector: {}

  image: jasonb87/compute-kube-monitor
  imageTag: 0.1.0

  imagePullPolicy: Always

  # Number of seconds between checking whether resources are ready to be cleaned up
  timeout: 600

  # The namespace to monitor
  namespace:

  resources: {}

dask:
  image: jasonb87/compute-celery
  imageTag: 0.1.0

  imagePullPolicy: Always

  # Number of workers per user
  workers: 10

  # Number of threads per worker
  nthreads: 4
  # Number of processes per worker
  nprocs: 1
  # Memory limit for each worker
  memoryLimit: 8GB

  resources: {}

  scheduler:
    nodeSelector: {}

    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: /daskboard/metrics
      prometheus.io/port: "8787"

    ingress:
      annotations: {}

      labels:
        traffic-type: external

    resources: {}

nginx:
  nodeSelector: {}

  replicas: 1
  image: jasonb87/compute-webapp
  imageTag: 0.1.0

  resources: {}

  ingress:
    annotations: {}

    labels:
      traffic-type: external
  
wps:
  nodeSelector: {}

  replicas: 1
  image: jasonb87/compute-wps
  imageTag: 0.1.0
  imagePullPolicy: Always

  # Set to external hostname of cluster
  externalHost: 
  allowedCIDR: 172.17.0.0/16

  apiUsername:
  apiPassword:

  # Set prometheus server to use for metrics collection
  prometheus:
    host:

  publicPath: /data/public

  adminEmail:

  # Configure the values that will be used in creating WPS responses
  title: "LLNL WPS Server"
  abstract: "LLNL WPS Compute Service"
  keywords:
    - "WPS"

  provider:
    name: "Jason B."
    site: "https://aims2.llnl.gov"

  contact:
    name:
    position:
    phone:

  address: 
    delivery:
    city:
    area:
    postal:
    counter:
    email:

  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: /api/metrics/
    prometheus.io/port: "8000"

  resources: {}

  # OAuth configuration
  oauth:
    client:
    secret:

  email:
    host: 
    port: 25
    user: ""
    password: ""

  ports:
    - name: django
      port: 8000

  ingress:
    annotations:
      ingress.kubernetes.io/ssl-redirect: "true"
      ingress.kubernetes.io/hsts-max-age: "31536000"
      ingress.kubernetes.io/hsts-include-subdomains: "true"
      ingress.kubernetes.io/force-hsts: "true"
    external:
      labels:
        traffic-type: external
    internal:
      labels:
        traffic-type: internal

celery:
  nodeSelector: {}

  image: jasonb87/compute-celery
  imageTag: 0.1.0
  metrics: /metrics

  imagePullPolicy: Always

  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 512Mi

  prometheusUrl:

  backend:
    development: false

    resources: {}

  # Each entry will create a new celery queue
  queues:
  - name: ingress
    replicas: 1
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: /metrics
      prometheus.io/port: "8080"
    ports:
      - port: 8080
        name: metrics

thredds:
  nodeSelector: {}

  replicas: 1
  image: jasonb87/compute-thredds
  imageTag: 4.6.10

  # Set java parameters for tomcat server
  heapMax: 2g
  heapInit: 512m

  resources: {}

  ingress:
    path: /threddsCWT

    annotations: {}

    labels:
      traffic-type: external

postgresql:
  postgresqlUsername: postgres
  postgresqlPassword:
  port: 5432

  master:
    nodeSelector: {}

  persistence:
    enabled: true
    existingClaim: postgresql-pvc

  backup:
    enabled: false
    image: bitnami/postgresql
    tag: 10.6.0

  resources: {}

redis:
  cluster:
    enabled: false

  usePassword: false

  # Cannot use permission init container when using existing claim 
  # chown -R 1001:1001
  persistence:
    existingClaim: redis-pvc

  master:
    service:
      type: ClusterIP

    resources: {}

    nodeSelector: {}
