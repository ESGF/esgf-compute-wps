apiVerison: apps/v1
kind: Deployment
metadata:
  name: dask-worker-{{ user }}
  labels:
    app.kubernetes.io/dask-component: worker
    app.kubernetes.io/user: "{{ user }}"
spec:
  replicas: {{ workers }}
  selector:
    matchLabels:
      app.kubernetes.io/dask-component: worker
      app.kubernetes.io/user: "{{ user }}"
  template:
    metadata:
      labels:
        app.kubernetes.io/dask-component: worker
        app.kubernetes.io/user: "{{ user }}"
    spec:
      containers:
      - name: dask-worker-{{ user }}
        image: jasonb87/compute-celery:0.1.0
        imagePullPolicy: Always
        livenessProbe:
          tcpSocket:
            port: 8888
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 8888
          initialDelaySeconds: 5
          periodSeconds: 10
        env:
        - name: CDAT_ANONYMOUS_LOG
          value: 'no'
        command:
        - dask-worker
        - --no-bokeh
        - --nthreads
        - '4'
        - --nprocs
        - '1'
        - --memory-limit
        - 8GB
        - --death-timeout
        - '60'
        - --listen-address
        - tcp://0.0.0.0:8888
        - dask-scheduler-{{ user }}:8786
      {% if not dev %}
        resources:
          limits:
            cpu: 4
            memory: 8Gi
          request:
            cpu: 4
            memory: 8Gi
      {% endif %}
        volumeMounts:
        - mountPath: {{ data_path }}
          name: public-volume
      volumes:
      - name: public-volume
        persistentVolumeClaim:
          claimName: {{ data_pvc }}
